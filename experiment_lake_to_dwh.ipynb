{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This experiment notebook is the base for the lake_to_dwh.py file. It will read/load the newspaper htmls, transform them and prepare the features, which are needed for an easy analyse. The analyse will be about the word \"klima\" and its changing use over time by newspaper. See Readme for more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import logging\n",
    "sys.path.append(os.path.abspath(\"pylib\"))\n",
    "\n",
    "import pandas as pd\n",
    "from handle_sqlite import save_dataframe_to_db, read_table_as_dataframe\n",
    "from handle_data_processing import process_newspaper_with_context\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load all the newspapers\n",
    "Here we will load the csv for one day."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test: saving df as sqlite and read it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = {'Name': ['Tom', 'nick', 'chris', 'jack'],\n",
    "        'Age': [20, 21, 19, 18]}\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(test)\n",
    "# df (pd.DataFrame): The DataFrame to save.\n",
    "# table_name (str): The name of the table in the database.\n",
    "# connection (sqlite3.Connection): SQLite connection object.\n",
    "# if_exists (str): How to behave if the table already exists. Options are 'fail', 'replace', 'append'.\n",
    "save_dataframe_to_db(df, \"test_table\", \"data_output/dwh_data.db\", \"replace\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "read_table_as_dataframe(\"test_table\", \"data_output/dwh_data.db\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " orchestrate the processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newspapers = [\n",
    "    {\"file_name\": \"data_input/data_lake/2021-04-02-54books.html\", \"encoding\": \"utf-8\", \"name\": \"54books\", \"date\": \"2021-04-02\"},\n",
    "    {\"file_name\": \"data_input/data_lake/2021-04-02-abendblatt.html\", \"encoding\": \"utf-8\", \"name\": \"abendblatt\", \"date\": \"2021-04-02\"},\n",
    "    {\"file_name\": \"data_input/data_lake/2025-01-14-vice-de.html\", \"encoding\": \"utf-8\", \"name\": \"vice\", \"date\": \"2025-01-24\"},\n",
    "    {\"file_name\": \"data_input/data_lake/2021-04-24-tagesschau.html\", \"encoding\": \"utf-8\", \"name\": \"tagesschaus\", \"date\": \"2021-04-24\"},\n",
    "    {\"file_name\": \"data_input/data_lake/2025-01-24-tagesschau.html\", \"encoding\": \"utf-8\", \"name\": \"tagesschaus\", \"date\": \"2025-01-24\"},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_collection = []\n",
    "context_collection = []\n",
    "\n",
    "for newspaper in newspapers:\n",
    "    try:\n",
    "        metadata, context_data = process_newspaper_with_context(newspaper)\n",
    "                \n",
    "        # Add a unique ID for each newspaper in the metadata and add to context\n",
    "        newspaper_id = len(metadata_collection) + 1  # This can be a simple counter for unique IDs (or use UUID)\n",
    "        metadata[\"newspaper_id\"] = newspaper_id  # Add newspaper_id to metadata\n",
    "        \n",
    "        # Append the metadata to its respective collection\n",
    "        metadata_collection.append(metadata)\n",
    "        \n",
    "        # Append the context data with id to its respective collection if 'klima' was found at least once\n",
    "        if metadata['klima_mentions_count'] > 0:\n",
    "            # First add the same newspaper_id to each context data\n",
    "            for context in context_data:\n",
    "                context[\"newspaper_id\"] = newspaper_id\n",
    "            context_collection.extend(context_data) # Using extend here because context_data is already a list of dicts\n",
    "\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error processing {newspaper['name']} for {newspaper['date']}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to DataFrame after processing all newspapers\n",
    "final_metadata_df = pd.DataFrame(metadata_collection)\n",
    "final_context_df = pd.DataFrame(context_collection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the results to the database\n",
    "save_dataframe_to_db(final_metadata_df, \"newspapers\", db_path=\"data_output/dwh_data.db\", if_exists=\"replace\")\n",
    "save_dataframe_to_db(final_context_df, \"context\", db_path=\"data_output/dwh_data.db\", if_exists=\"replace\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "read_table_as_dataframe(\"newspapers\", \"data_output/dwh_data.db\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for every collected path open and process the newspaper and append result to list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_metadata_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_context_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "take list and append to sqlite."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df['pre_context']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df['post_context']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10",
   "language": "python",
   "name": "python3.10"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
