{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "here we want to\n",
    "- count klima by time to see if number rises or shrinks\n",
    "- dynamik je lemma/CAGR over '21 - '25\n",
    "- wochentagsvergleich und monatsweise\n",
    "- fuzzy match the suffixes so we can\n",
    "    (- analyse the top suffix in total)\n",
    "    - see progress of tops ranking over time (rolling by week/month)\n",
    "    - see all of these arising top suffixes in comparison over time by relative part (ANTEIL)\n",
    "- see over time the entropy/diversity of the klima suffix (keeping same, getting smaller?) / Outlet-Heterogenit채t: Gini/Herfindahl\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from textblob import TextBlob\n",
    "\n",
    "# make helper methods available\n",
    "# Add custom library path relative to notebook location\n",
    "notebook_dir = os.path.dirname(os.path.abspath(__file__)) if '__file__' in globals() else os.getcwd()\n",
    "sys.path.append(os.path.join(notebook_dir, \"..\", \"pylib\"))\n",
    "\n",
    "\n",
    "from handle_sqlite import read_table_as_dataframe\n",
    "\n",
    "db_path = os.path.join(notebook_dir, \"..\", \"data_output\", \"dwh_data.db\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global Seaborn settings\n",
    "sns.set_theme(style=\"whitegrid\", context=\"talk\", palette=\"deep\")\n",
    "plt.rcParams[\"figure.figsize\"] = (12, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load from dwh the newspaper informations per date and their usage of klima\n",
    "metadata = read_table_as_dataframe(\"newspapers_processed\", db_path)\n",
    "display(metadata.head(3))\n",
    "\n",
    "# load from dwh the found klima words\n",
    "context = read_table_as_dataframe(\"context_processed\", db_path)\n",
    "display(context.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "context = context.astype({'pre_context': 'string',\n",
    "                         'post_context': 'string',\n",
    "                         'prefix': 'string',\n",
    "                         'suffix': 'string',})\n",
    "context.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check again data sanity\n",
    "context[~context['newspaper_id'].isin(metadata['newspaper_id'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 'data_published' to datetime for proper time-based aggregation\n",
    "metadata['data_published'] = pd.to_datetime(metadata['data_published'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the two dataframes on 'newspaper_id'\n",
    "merged = pd.merge(context, metadata, on=\"newspaper_id\", how=\"inner\")\n",
    "\n",
    "# Checking the number of unique newspaper_id in both tables\n",
    "print(f\"Unique newspaper_id in metadata: {metadata['newspaper_id'].nunique()}\")\n",
    "print(f\"Unique newspaper_id in context: {context['newspaper_id'].nunique()}\")\n",
    "print(f\"Unique newspaper_id in merged: {merged['newspaper_id'].nunique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Anteil Klima-Komposita (klima_mentions_count from newspaper) an allen Headlines (30-Tage-Rolling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the average number of klima mentions per newspaper per day\n",
    "# Group by date, sum klima_mentions_count and count newspapers\n",
    "daily_stats = (\n",
    "    metadata.groupby('data_published')\n",
    "    .agg(total_klima_mentions=('klima_mentions_count', 'sum'),\n",
    "         num_newspapers=('newspaper_name', 'count'))\n",
    "    .reset_index()\n",
    "    .sort_values('data_published')\n",
    ")\n",
    "\n",
    "# Calculate average klima mentions per newspaper per day\n",
    "daily_stats['avg_klima_per_newspaper'] = daily_stats['total_klima_mentions'] / daily_stats['num_newspapers']\n",
    "\n",
    "# Plot the average as a line chart\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.lineplot(x='data_published', y='avg_klima_per_newspaper', data=daily_stats, color='steelblue')\n",
    "plt.xlabel('Date Published')\n",
    "plt.ylabel('Avg Klima Mentions per Newspaper')\n",
    "plt.title('Average Klima Mentions per Newspaper per Day')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Aggregate total klima mentions per day\n",
    "daily_klima = metadata.groupby('data_published')['klima_mentions_count'].sum().reset_index()\n",
    "\n",
    "# Sort by date\n",
    "daily_klima = daily_klima.sort_values('data_published')\n",
    "\n",
    "# Calculate 30-day rolling sum\n",
    "daily_klima['klima_mentions_30d'] = daily_klima['klima_mentions_count'].rolling(window=1).sum()\n",
    "\n",
    "# Plot the rolling sum as a line chart\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.lineplot(x='data_published', y='klima_mentions_30d', data=daily_klima, color='steelblue')\n",
    "plt.xlabel('Date Published')\n",
    "plt.ylabel('30-Day Rolling Sum of Klima Mentions')\n",
    "plt.title('Rolling 30-Day Sum of Klima Mentions per Day')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Aggregate total klima mentions per day\n",
    "daily_klima = metadata.groupby('data_published')['klima_mentions_count'].sum().reset_index()\n",
    "\n",
    "# Sort by date\n",
    "daily_klima = daily_klima.sort_values('data_published')\n",
    "\n",
    "# Calculate 30-day rolling sum\n",
    "daily_klima['klima_mentions_30d'] = daily_klima['klima_mentions_count'].rolling(window=30).sum()\n",
    "\n",
    "# Plot the rolling sum as a line chart\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.lineplot(x='data_published', y='klima_mentions_30d', data=daily_klima, color='steelblue')\n",
    "plt.xlabel('Date Published')\n",
    "plt.ylabel('30-Day Rolling Sum of Klima Mentions')\n",
    "plt.title('Rolling 30-Day Sum of Klima Mentions per Day')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "yearly_avg = daily_klima.groupby('year')['klima_mentions_30d'].mean()\n",
    "\n",
    "for year, avg in yearly_avg.items():\n",
    "    plt.axhline(avg, linestyle='--', label=f'{year} avg')\n",
    "\n",
    "plt.legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.dates as mdates\n",
    "\n",
    "# Basisdaten\n",
    "daily_klima = (\n",
    "    merged.groupby('data_published')['klima_mentions_count']\n",
    "    .sum()\n",
    "    .reset_index()\n",
    "    .sort_values('data_published')\n",
    ")\n",
    "daily_klima['klima_mentions_30d'] = daily_klima['klima_mentions_count'].rolling(window=30, min_periods=1).sum()\n",
    "daily_klima['year'] = daily_klima['data_published'].dt.year\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "# 1) Rolling-Kurve\n",
    "sns.lineplot(x='data_published', y='klima_mentions_30d',\n",
    "             data=daily_klima, color='steelblue', ax=ax, label='30d rolling sum')\n",
    "\n",
    "# 2) Trendlinie pro Jahr mit polyfit\n",
    "for year, dfy in daily_klima.groupby('year'):\n",
    "    if len(dfy) < 2:  # zu wenige Punkte\n",
    "        continue\n",
    "\n",
    "    x_num = mdates.date2num(dfy['data_published'])\n",
    "    y = dfy['klima_mentions_30d'].values\n",
    "\n",
    "    # lineares Fit (Grad=1)\n",
    "    coeffs = np.polyfit(x_num, y, deg=1)\n",
    "    poly = np.poly1d(coeffs)\n",
    "\n",
    "    # Wertebereich f체r dieses Jahr\n",
    "    x_line = np.linspace(x_num.min(), x_num.max(), 100)\n",
    "    y_line = poly(x_line)\n",
    "\n",
    "    ax.plot(mdates.num2date(x_line), y_line, lw=2, label=f'{year} trend')\n",
    "\n",
    "# 3) Achsenformatierung\n",
    "locator = mdates.AutoDateLocator()\n",
    "formatter = mdates.ConciseDateFormatter(locator)\n",
    "ax.xaxis.set_major_locator(locator)\n",
    "ax.xaxis.set_major_formatter(formatter)\n",
    "\n",
    "ax.set_xlabel('Date Published')\n",
    "ax.set_ylabel('30-Day Rolling Sum of Klima Mentions')\n",
    "ax.set_title('Rolling 30-Day Sum with Yearly Linear Trendlines (polyfit)')\n",
    "ax.legend(ncol=3, fontsize=9)\n",
    "ax.grid(True, linewidth=0.5, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.dates as mdates\n",
    "\n",
    "# Basisdaten\n",
    "daily_klima = (\n",
    "    merged.groupby('data_published')['klima_mentions_count']\n",
    "    .sum()\n",
    "    .reset_index()\n",
    "    .sort_values('data_published')\n",
    ")\n",
    "daily_klima['klima_mentions_30d'] = daily_klima['klima_mentions_count'].rolling(window=30, min_periods=1).sum()\n",
    "daily_klima['year'] = daily_klima['data_published'].dt.year\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "# 1) Rolling-Kurve\n",
    "sns.lineplot(x='data_published', y='klima_mentions_30d',\n",
    "             data=daily_klima, color='steelblue', ax=ax, label='30d rolling sum')\n",
    "\n",
    "# 2) Trendlinie pro Jahr mit polyfit\n",
    "for year, dfy in daily_klima.groupby('year'):\n",
    "    if len(dfy) < 2:  # zu wenige Punkte\n",
    "        continue\n",
    "\n",
    "    x_num = mdates.date2num(dfy['data_published'])\n",
    "    y = dfy['klima_mentions_30d'].values\n",
    "\n",
    "    # lineares Fit (Grad=1)\n",
    "    coeffs = np.polyfit(x_num, y, deg=1)\n",
    "    poly = np.poly1d(coeffs)\n",
    "\n",
    "    # Wertebereich f체r dieses Jahr\n",
    "    x_line = np.linspace(x_num.min(), x_num.max(), 100)\n",
    "    y_line = poly(x_line)\n",
    "\n",
    "    ax.plot(mdates.num2date(x_line), y_line, lw=2, label=f'{year} trend')\n",
    "\n",
    "# 3) Achsenformatierung\n",
    "locator = mdates.AutoDateLocator()\n",
    "formatter = mdates.ConciseDateFormatter(locator)\n",
    "ax.xaxis.set_major_locator(locator)\n",
    "ax.xaxis.set_major_formatter(formatter)\n",
    "\n",
    "ax.set_xlabel('Date Published')\n",
    "ax.set_ylabel('30-Day Rolling Sum of Klima Mentions')\n",
    "ax.set_title('Rolling 30-Day Sum with Yearly Linear Trendlines (polyfit)')\n",
    "ax.legend(ncol=3, fontsize=9)\n",
    "ax.grid(True, linewidth=0.5, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.dates as mdates\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Basisdaten\n",
    "daily_klima = (\n",
    "    merged.groupby('data_published')['klima_mentions_count']\n",
    "    .sum()\n",
    "    .reset_index()\n",
    "    .sort_values('data_published')\n",
    ")\n",
    "daily_klima['klima_mentions_30d'] = (\n",
    "    daily_klima['klima_mentions_count']\n",
    "    .rolling(window=30, min_periods=1).sum()\n",
    ")\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "# 1) Rolling-Kurve\n",
    "sns.lineplot(\n",
    "    x='data_published', y='klima_mentions_30d',\n",
    "    data=daily_klima, color='steelblue', ax=ax, label='30d rolling sum'\n",
    ")\n",
    "\n",
    "# 2) Polynomtrend 체ber alle Jahre\n",
    "x_num = mdates.date2num(daily_klima['data_published'])\n",
    "y = daily_klima['klima_mentions_30d'].values\n",
    "\n",
    "# Fit mit Grad 3 (anpassen: 2=quadratisch, 4=glatter etc.)\n",
    "coeffs = np.polyfit(x_num, y, deg=3)\n",
    "poly = np.poly1d(coeffs)\n",
    "\n",
    "x_line = np.linspace(x_num.min(), x_num.max(), 300)\n",
    "y_line = poly(x_line)\n",
    "\n",
    "ax.plot(mdates.num2date(x_line), y_line,\n",
    "        color='darkred', lw=2, label='Polynomial Trend (deg=3)')\n",
    "\n",
    "# 3) Achsenformatierung\n",
    "locator = mdates.AutoDateLocator()\n",
    "formatter = mdates.ConciseDateFormatter(locator)\n",
    "ax.xaxis.set_major_locator(locator)\n",
    "ax.xaxis.set_major_formatter(formatter)\n",
    "\n",
    "ax.set_xlabel('Date Published')\n",
    "ax.set_ylabel('30-Day Rolling Sum of Klima Mentions')\n",
    "ax.set_title('Rolling 30-Day Sum with Polynomial Trendline')\n",
    "ax.legend()\n",
    "ax.grid(True, linewidth=0.5, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dot plot to visualize outliers in daily klima mentions\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "# Scatter plot for each day\n",
    "ax.scatter(daily_klima['data_published'], daily_klima['klima_mentions_count'], color='steelblue', alpha=0.7, label='Daily Klima Mentions')\n",
    "\n",
    "ax.set_xlabel('Date Published')\n",
    "ax.set_ylabel('Klima Mentions per Day')\n",
    "ax.set_title('Dot Plot of Daily Klima Mentions (Outlier Detection)')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20",
   "metadata": {},
   "source": [
    "### kpis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- KPIs: Klima Mentions Overview ---\n",
    "\n",
    "# Total klima mentions\n",
    "total_klima_mentions = metadata['klima_mentions_count'].sum()\n",
    "print(f\"Total klima mentions: {total_klima_mentions}\")\n",
    "\n",
    "# Klima mentions per year\n",
    "metadata['year'] = metadata['data_published'].dt.year\n",
    "klima_per_year = metadata.groupby('year')['klima_mentions_count'].sum()\n",
    "print(\"\\nKlima mentions per year:\")\n",
    "print(klima_per_year)\n",
    "\n",
    "# Klima mentions per newspaper (outlet)\n",
    "klima_per_newspaper = metadata.groupby('newspaper_name')['klima_mentions_count'].sum().sort_values(ascending=False)\n",
    "print(\"\\nKlima mentions per newspaper:\")\n",
    "print(klima_per_newspaper)\n",
    "\n",
    "# Average klima mentions per newspaper per year\n",
    "avg_klima_per_newspaper_year = metadata.groupby(['year', 'newspaper_name'])['klima_mentions_count'].mean().unstack().fillna(0)\n",
    "print(\"\\nAverage klima mentions per newspaper per year:\")\n",
    "print(avg_klima_per_newspaper_year)\n",
    "\n",
    "# Number of newspapers per year\n",
    "newspapers_per_year = metadata.groupby('year')['newspaper_name'].nunique()\n",
    "print(\"\\nNumber of newspapers per year:\")\n",
    "print(newspapers_per_year)\n",
    "\n",
    "# Number of days with at least one klima mention\n",
    "days_with_klima = (metadata.groupby('data_published')['klima_mentions_count'].sum() > 0).sum()\n",
    "print(f\"\\nNumber of days with at least one klima mention: {days_with_klima}\")\n",
    "\n",
    "# Number of newspapers with zero klima mentions (all time)\n",
    "zero_klima_newspapers = klima_per_newspaper[klima_per_newspaper == 0]\n",
    "print(\"\\nNewspapers with zero klima mentions:\")\n",
    "print(zero_klima_newspapers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Average Klima Mentions per Weekday and Month ---\n",
    "\n",
    "# --- Klima Mentions by Weekday and Month ---\n",
    "\n",
    "# Add weekday and month columns\n",
    "metadata['weekday'] = metadata['data_published'].dt.day_name()\n",
    "metadata['month'] = metadata['data_published'].dt.month_name()\n",
    "\n",
    "# Aggregate klima mentions by weekday\n",
    "weekday_stats = metadata.groupby('weekday')['klima_mentions_count'].sum().reindex([\n",
    "    'Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday'\n",
    "])\n",
    "\n",
    "# Count number of each weekday in the dataset\n",
    "weekday_counts = metadata['weekday'].value_counts().reindex([\n",
    "    'Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday'\n",
    "])\n",
    "\n",
    "# Calculate average klima mentions per weekday\n",
    "avg_klima_per_weekday = weekday_stats / weekday_counts\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.barplot(x=avg_klima_per_weekday.index, y=avg_klima_per_weekday.values)\n",
    "plt.xlabel('Weekday')\n",
    "plt.ylabel('Avg Klima Mentions per Day')\n",
    "plt.title('Average Klima Mentions per Weekday')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Count number of each month in the dataset\n",
    "month_counts = metadata['month'].value_counts().reindex(month_order)\n",
    "\n",
    "# Calculate average klima mentions per month\n",
    "avg_klima_per_month = month_stats / month_counts\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.barplot(x=avg_klima_per_month.index, y=avg_klima_per_month.values)\n",
    "plt.xlabel('Month')\n",
    "plt.ylabel('Avg Klima Mentions per Day')\n",
    "plt.title('Average Klima Mentions per Month')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "month_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Check missing months and newspapers ---\n",
    "# Find which months are missing or have few entries\n",
    "print(\"Number of unique publication days per month:\")\n",
    "print(metadata.groupby('month')['data_published'].nunique())\n",
    "\n",
    "# List all newspapers present in February\n",
    "feb_papers = metadata[metadata['month'] == 'February']['newspaper_name'].unique()\n",
    "print(\"Newspapers present in February:\")\n",
    "print(feb_papers)\n",
    "\n",
    "# List all publication dates in February\n",
    "feb_dates = metadata[metadata['month'] == 'February']['data_published'].unique()\n",
    "print(\"Publication dates in February:\")\n",
    "print(feb_dates)\n",
    "\n",
    "# If needed, show which newspapers are missing in February compared to other months\n",
    "all_papers = set(metadata['newspaper_name'].unique())\n",
    "feb_papers_set = set(feb_papers)\n",
    "missing_in_feb = all_papers - feb_papers_set\n",
    "print(\"Newspapers missing in February:\")\n",
    "print(missing_in_feb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "import calendar\n",
    "\n",
    "# count unique publication days per calendar month (across all years)\n",
    "unique_days_per_month = (\n",
    "    metadata.groupby(metadata['data_published'].dt.month)['data_published']\n",
    "    .nunique()\n",
    "    .reindex(range(1, 13), fill_value=0)\n",
    ")\n",
    "unique_days_per_month.index = [calendar.month_name[m] for m in unique_days_per_month.index]\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "sns.barplot(x=unique_days_per_month.index, y=unique_days_per_month.values, color='steelblue')\n",
    "plt.xlabel('Month')\n",
    "plt.ylabel('Unique publication days')\n",
    "plt.title('Number of Unique Publication Days per Month (all years)')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
